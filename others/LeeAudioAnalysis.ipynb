{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K7ixOuOgxeJ9"
      },
      "outputs": [],
      "source": [
        "import os, librosa, numpy as np, pandas as pd, statistics, scipy, re, pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVpE3Cvxirx",
        "outputId": "bc034156-e32e-4482-dba7-b817c939ac70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9DRwPXcYbjVG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScLWtk_l03iU"
      },
      "source": [
        "\"\"efficient implementation approach\" cf. some paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Rl17cfvn0ww1",
        "outputId": "371dd813-c9e7-4a6f-da80-f1833b1861ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uniq_id       date  month    year  d2014  d2015  d2016  q1_14  q2_14  \\\n",
              "0      1.0 2014-02-08    2.0  2014.0    1.0    0.0    0.0    1.0    0.0   \n",
              "1      2.0 2014-02-08    2.0  2014.0    1.0    0.0    0.0    1.0    0.0   \n",
              "2      3.0 2014-02-08    2.0  2014.0    1.0    0.0    0.0    1.0    0.0   \n",
              "3      4.0 2014-02-08    2.0  2014.0    1.0    0.0    0.0    1.0    0.0   \n",
              "4      5.0 2014-02-08    2.0  2014.0    1.0    0.0    0.0    1.0    0.0   \n",
              "\n",
              "   q3_14  ...  way  well  were  what  when  where  who  will  with yeah  \n",
              "0    0.0  ...  0.0   0.0   0.0   1.0   1.0    0.0  1.0   0.0   1.0  1.0  \n",
              "1    0.0  ...  0.0   0.0   0.0   1.0   0.0    0.0  0.0   0.0   1.0  1.0  \n",
              "2    0.0  ...  0.0   0.0   0.0   1.0   0.0    1.0  0.0   0.0   0.0  1.0  \n",
              "3    0.0  ...  0.0   0.0   0.0   0.0   0.0    1.0  0.0   1.0   0.0  1.0  \n",
              "4    0.0  ...  0.0   0.0   0.0   1.0   1.0    0.0  0.0   0.0   0.0  1.0  \n",
              "\n",
              "[5 rows x 161 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-989d806c-d73f-4339-beb4-d4a7cc18bbb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniq_id</th>\n",
              "      <th>date</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>d2014</th>\n",
              "      <th>d2015</th>\n",
              "      <th>d2016</th>\n",
              "      <th>q1_14</th>\n",
              "      <th>q2_14</th>\n",
              "      <th>q3_14</th>\n",
              "      <th>...</th>\n",
              "      <th>way</th>\n",
              "      <th>well</th>\n",
              "      <th>were</th>\n",
              "      <th>what</th>\n",
              "      <th>when</th>\n",
              "      <th>where</th>\n",
              "      <th>who</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>yeah</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-02-08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2014-02-08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2014-02-08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2014-02-08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2014-02-08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 161 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-989d806c-d73f-4339-beb4-d4a7cc18bbb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-989d806c-d73f-4339-beb4-d4a7cc18bbb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-989d806c-d73f-4339-beb4-d4a7cc18bbb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "os.chdir(r\"/content/drive/MyDrive/Tracks\")\n",
        "df = pd.read_excel(r\"/content/drive/MyDrive/You_S1_Data_NoBillboardRanking.xlsx\")\n",
        "df = df.sort_values(by=['uniq_id'])\n",
        "df = df.reset_index(drop=True)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kNJ1yQjpkGJi"
      },
      "outputs": [],
      "source": [
        "#Cast Song Title from float (to int) to string\n",
        "floatRowsMask = np.where([isinstance(x, float) for x in  df.song])\n",
        "df.song.iloc[floatRowsMask] = df.loc[floatRowsMask, \"song\"].astype('int').astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YiFe1OBzqEsb"
      },
      "outputs": [],
      "source": [
        "#Rename all files in Tracks folder to lower case\n",
        "path = \"/content/drive/MyDrive/Tracks/\"\n",
        "for file in os.listdir(path):\n",
        "    os.rename(path + file, path + file.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lY_mLUPLAQQc"
      },
      "outputs": [],
      "source": [
        "for x in range(len(df.date)): #2022QuickFix\n",
        "    song_temp = df[\"song\"][x] \n",
        "    song_temp = re.sub(\"[/:\\\"]\", \"\", song_temp)\n",
        "    song_temp = re.sub(\"[/:\\\"]\", \"\", song_temp)\n",
        "    song_temp = re.sub(\"[\\?\\*]\", \"#\", song_temp)\n",
        "    song_temp = re.sub(\"腎\", \"t\", song_temp)\n",
        "    song_temp = song_temp.lower()\n",
        "    if song_temp.find(\"(\") != -1: song_temp = song_temp[:song_temp.find(\"(\")-1] + song_temp[song_temp.find(\")\")+1:] \n",
        "    df[\"song\"][x] = re.sub(\"ac/dc\", \"acdc\", song_temp)\n",
        "    artist_temp = df[\"artist\"][x] \n",
        "    artist_temp = re.sub(\"[/:\\\"]\", \"\", artist_temp)\n",
        "    artist_temp = re.sub(\"[\\?\\*]\", \"#\", artist_temp)\n",
        "    artist_temp = artist_temp.lower()\n",
        "    df[\"artist\"][x] = re.sub(\"ac/dc\", \"acdc\", artist_temp)\n",
        "\n",
        "##Control loop to check if error occurs (ie. song not found in folder)\n",
        "# for x in range(len(df.date)):\n",
        "#     b = df[\"song\"][x] #2022QuickFix\n",
        "#     if b.find(\"(\") != -1: \n",
        "#       b = b[:b.find(\"(\")-1] + b[b.find(\")\")+1:]  #2022QuickFix\n",
        "#       df[\"song\"][x] = b\n",
        "#     a = b + \" - \" + df[\"artist\"][x]  \n",
        "#     if a.lower() in [x[:-4] for x in os.listdir()]:\n",
        "#         pass\n",
        "#     else:\n",
        "#         print(a)\n",
        "#         print(df[\"artist_song\"][x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmWm9YMwxsd6",
        "outputId": "4e171784-ea23-43c4-d235-9e11d3d4e20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oceans 0\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "beautiful day 1\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "overcomer 2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "this is amazing grace 3\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "shake 4\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "write your story 5\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "10,000 reasons 6\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "lord i need you 7\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "how to save a life 8\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "all you've ever wanted 9\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "keep making me 10\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "i can only imagine 11\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "whom shall i fear 12\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "love alone is worth the fight 13\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "i am 14\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "monster 15\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "you found me 16\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "thrive 17\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "the only name 18\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "difference maker 19\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "the heart 20\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "jesus, take the wheel 21\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "god's not dead 22\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "hello, my name is 23\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "speak life 24\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "redeemed 25\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "good morning 26\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "hero 27\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "gold 28\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "broken hallelujah 29\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "not gonna die 30\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "this is now 31\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "worn 32\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "you and me 33\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "our god 34\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "i don't deserve you 35\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "awake and alive 36\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "let them see you 37\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "your grace finds me 38\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "how great thou art 39\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "who we are 40\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "praise you in this storm 41\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "amazing grace 42\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "j_chroma = range(3, 9)\n",
        "hop_length = 512\n",
        "def kl_divergence(p, q):\n",
        "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
        "def d(s1, s2):\n",
        "    M = (s1 + s2) / 2\n",
        "    return (kl_divergence(s1, M) + kl_divergence(s2, M)) / 2\n",
        "def s_eff(a,b):\n",
        "    return matrixC[b] - matrixC[a]\n",
        "\n",
        "def eucl_dist(a,b):\n",
        "    return np.linalg.norm(a-b)\n",
        "\n",
        "scChromaOUT = []\n",
        "for ii in range(len(df.date)):\n",
        "    if df.song[ii] not in [x[0] for x in scChromaOUT]:\n",
        "        print(df.song[ii],ii)\n",
        "        x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii],df.artist[ii]))\n",
        "        chromagram = pd.DataFrame(librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length, )).transpose()\n",
        "        matrixC = []\n",
        "        for i in range(len(chromagram[1])):\n",
        "            matrixC.append(sum(np.array(chromagram.iloc[0:i+1])))\n",
        "        scChroma = []\n",
        "        v_eff=[]\n",
        "        for j in j_chroma:\n",
        "            w = 2 ** (j - 1)\n",
        "            v_eff = []\n",
        "            for i in range(len(chromagram[1])):\n",
        "                if i>w and i<len(chromagram[1])-w:\n",
        "                    v_eff.append(d(s_eff(i - w + 1, i - 1), s_eff(i, i + w)))\n",
        "                else:\n",
        "                    v_eff.append(0)\n",
        "            scChroma.append(statistics.mean(v_eff))\n",
        "        scChromaOUT.append((df.song[ii],df.artist[ii],scChroma))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BJ7EnuFlfIui"
      },
      "outputs": [],
      "source": [
        "#with open('/content/drive/MyDrive/scChromaOUT1.pkl', 'wb') as f:\n",
        "#  pickle.dump(scChromaOUT, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/scChromaOUT1.pkl', 'rb') as f:\n",
        "   scChromaOUT = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[x for x in range(len(scChromaOUT)) if \"mean\" in scChromaOUT[x][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee_dPeUZJiPt",
        "outputId": "fc70e69e-d817-47f0-cf86-da2c19f67d03"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[568, 633, 697, 944, 1245, 1695]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scChromaOUT[1695]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsk0FhI5J9g6",
        "outputId": "ae42f6be-e0f2-487b-d18e-4a053a3f66b8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('wat u mean',\n",
              " 'dae dae',\n",
              " [1.747603797549854,\n",
              "  1.9804192044687103,\n",
              "  2.3437729975855706,\n",
              "  2.9493167563332943,\n",
              "  3.873596307142461,\n",
              "  6.491969528531878])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##scChromaOUT[105] = ('castaway',\n",
        "# 'zac brown band ',\n",
        "# [1.5286225971986438,\n",
        "#  1.9564730549538154,\n",
        "#  2.9522507891120457,\n",
        "#  4.643816268279218,\n",
        "#  6.6410810748934965,\n",
        "#  6.702313356935985])"
      ],
      "metadata": {
        "id": "zzsHiIX-KKAK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kMQxgOHn2atW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89187766-1e98-4563-8e59-73a5935814a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wat u meanwat u mean (aye, aye, aye\n"
          ]
        }
      ],
      "source": [
        "df[\"Chroma1\"],df[\"Chroma2\"],df[\"Chroma3\"],df[\"Chroma4\"],df[\"Chroma5\"],df[\"Chroma6\"]=0.0,0.0,0.0,0.0,0.0,0.0\n",
        "\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el=[y for y in scChromaOUT if y[0]==df.song[x]][0][-1]\n",
        "        df[\"Chroma1\"][x],df[\"Chroma2\"][x],df[\"Chroma3\"][x],df[\"Chroma4\"][x],df[\"Chroma5\"][x],df[\"Chroma6\"][x]=el\n",
        "    except:\n",
        "        print(df.song[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "WL0TvRbt2az4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a70185-917e-40b6-e398-1b5a8d969c55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1693    1.385494\n",
              "1694    1.718914\n",
              "1695    1.531141\n",
              "1696    1.519318\n",
              "1697    1.778577\n",
              "Name: Chroma1, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#df.Chroma1.loc[1693:1697]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.where(df.Chroma1==0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaajwiT-MPyT",
        "outputId": "bf00785b-5fac-4301-95c3-c1097c46bf3c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3737]),)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.song[3737]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9TK5JJxuMUk8",
        "outputId": "7cf82b59-858f-4d4b-9a4e-26acd2f0fa00"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wat u meanwat u mean (aye, aye, aye'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Rank\"] = np.tile(np.arange(50, 0, -1), 84)"
      ],
      "metadata": {
        "id": "DuZKBD6vNpip"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "my_cols = [\"Chroma1\",\"Chroma2\",\"Chroma3\",\"Chroma4\",\"Chroma5\",\"Chroma6\",]\n",
        "X = sm.add_constant(df[my_cols])\n",
        "results = sm.OLS(df.Rank, X).fit().summary()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLyT2L_ZNWlt",
        "outputId": "3e229948-1359-4e60-cd8a-3d8025db2fa9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                   Rank   R-squared:                       0.004\n",
            "Model:                            OLS   Adj. R-squared:                  0.003\n",
            "Method:                 Least Squares   F-statistic:                     2.879\n",
            "Date:                Mon, 05 Dec 2022   Prob (F-statistic):            0.00841\n",
            "Time:                        16:55:32   Log-Likelihood:                -17162.\n",
            "No. Observations:                4200   AIC:                         3.434e+04\n",
            "Df Residuals:                    4193   BIC:                         3.438e+04\n",
            "Df Model:                           6                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         20.6415      3.774      5.469      0.000      13.242      28.041\n",
            "Chroma1       -2.2713      2.876     -0.790      0.430      -7.909       3.366\n",
            "Chroma2        4.2067      2.093      2.010      0.045       0.103       8.310\n",
            "Chroma3       -0.2917      1.472     -0.198      0.843      -3.177       2.594\n",
            "Chroma4        0.3472      0.892      0.389      0.697      -1.401       2.095\n",
            "Chroma5       -0.2936      0.395     -0.743      0.458      -1.068       0.481\n",
            "Chroma6        0.1811      0.136      1.336      0.182      -0.085       0.447\n",
            "==============================================================================\n",
            "Omnibus:                     3226.006   Durbin-Watson:                   0.241\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              247.433\n",
            "Skew:                          -0.006   Prob(JB):                     1.86e-54\n",
            "Kurtosis:                       1.811   Cond. No.                         304.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pO7YjfuNWoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "ybU2IaplocuR",
        "outputId": "50f1f9a3-128e-4bb2-d991-190bb28332b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oceans 0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "--- 552.8081092834473 seconds ---\n",
            "Beautiful Day 1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-00dfa7801fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mls_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowed_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mls_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindowed_segment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#mettere lol[0:x con x>len(lol)] funge lo stesso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;31m# Build a Mel filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/filters.py\u001b[0m in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# .. then intersect them with each other and zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"slaney\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "#timbre and arousal\n",
        "sr=44100\n",
        "win_len = round(sr * 2.97)\n",
        "win = np.hamming(win_len)\n",
        "j_timbre = range(1, 7)\n",
        "\n",
        "scTimbreOUT = []\n",
        "for ii in range(len(df.date)):\n",
        "    if df.song[ii] not in [x[0] for x in scTimbreOUT]:\n",
        "        start_time = time.time()\n",
        "        print(df.song[ii],ii)\n",
        "        x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii],df.artist[ii]),sr)\n",
        "        d = round(librosa.get_duration(x, sr=sr))  # in seconds, COME CONSIDERO IL ROUNDING?!?!?!?\n",
        "        i, ls = 0, []\n",
        "        while i < d * sr:\n",
        "            a = x[i:i + win_len]  # win_len = datapoints in that window interval, +i <-- il movimento di 1 sec, (+0,+44100, +44100*2, ecc)\n",
        "            if len(x[i:i + win_len]) < win_len: #per l'ultimo pezzo magari non lungo abbastanza\n",
        "                a = np.array(list(x[i:i + win_len]) + [0 for x in range(win_len - len(x[i:i + win_len]))])\n",
        "            windowed_segment = win * a\n",
        "            ls_t = []\n",
        "            for y in range(0, len(windowed_segment), 512):\n",
        "                ls_t.append([x[0] for x in librosa.feature.mfcc(windowed_segment[y:y + 512], sr=sr, n_mfcc=36).tolist()]) #mettere lol[0:x con x>len(lol)] funge lo stesso\n",
        "            df1 = pd.DataFrame(ls_t).transpose()\n",
        "            ls.append([statistics.mean(df1.iloc[x]) for x in range(len(df1[35]))])\n",
        "            #print((d*sr - i)//sr)\n",
        "            i += sr\n",
        "        df1 = pd.DataFrame(ls)\n",
        "\n",
        "        matrixC = []\n",
        "        for i in range(len(df1[35])):\n",
        "            matrixC.append(sum(np.array(df1.iloc[0:i+1])))\n",
        "        scTimbre = []\n",
        "        v_eff=[]\n",
        "        for j in j_timbre:\n",
        "            w = 2 ** (j - 1)\n",
        "            v_eff = []\n",
        "            print(j)\n",
        "            for i in range(len(df1[35])):\n",
        "                if i>w and i<len(df1[35])-w:\n",
        "                    v_eff.append(eucl_dist(s_eff(i - w + 1, i - 1), s_eff(i, i + w))) #kl div serve per le prob distro, non è quello che cerco, uso la eucledian distance https://groups.google.com/g/librosa/c/9Xs15kDImOg\n",
        "                else:\n",
        "                    v_eff.append(0)\n",
        "            scTimbre.append(statistics.mean(v_eff))\n",
        "        scTimbreOUT.append((df.song[ii],df.artist[ii],scTimbre))\n",
        "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "#\n",
        "sr=44100\n",
        "win_len = round(sr * 2.97)\n",
        "win = np.hamming(win_len)\n",
        "arousalOUT = []\n",
        "for ii in range(len(df.date)):\n",
        "    #if df.song[ii] not in [x[0] for x in arousalOUT] and df.artist[ii] not in [x[1] for x in arousalOUT]:\n",
        "    if (df.song[ii], df.artist[ii]) not in [(x[0],x[1]) for x in arousalOUT]:\n",
        "        #for el in os.listdir(os.getcwd()): #togli [:1] lool ma che cazzo avevo fatto\n",
        "        print(df.song[ii], ii)\n",
        "        x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii], df.artist[ii]), sr)\n",
        "        d = round(librosa.get_duration(x, sr=44100))  # in seconds, COME CONSIDERO IL ROUNDING?!?!?!?\n",
        "        i, arousal = 0, []\n",
        "        while i < d * sr:\n",
        "            a = x[i:i + win_len]  # win_len = datapoints in that window interval, +i <-- il movimento di 1 sec, (+0,+44100, +44100*2, ecc)\n",
        "            if len(x[i:i + win_len]) < win_len:\n",
        "                a = np.array(list(x[i:i + win_len]) + [0 for x in range(win_len - len(x[i:i + win_len]))])\n",
        "            windowed_segment = win * a\n",
        "            arousal.append(np.sum(np.abs(windowed_segment)))\n",
        "            #asaprint(d*sr - i)\n",
        "            i += sr\n",
        "        arousalOUT.append((df.song[ii],df.artist[ii],statistics.mean(arousal),statistics.stdev(arousal)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQfzI8gSmMDJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40m99GB6yWeZ"
      },
      "outputs": [],
      "source": [
        "# aa=[x for x in df.song]\n",
        "# aa=list(set(aa))\n",
        "# aaa=[x[0] for x in scChromaOUT]\n",
        "# aaaa=[x for x in aa if x not in aaa]\n",
        "\n",
        "# for ii in range(len(df.date)):\n",
        "#     print(ii)\n",
        "#     try:\n",
        "#         if df.song[ii] not in [x[0] for x in scChromaOUT]:\n",
        "#             print(df.song[ii],ii)\n",
        "#             x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii],df.artist[ii]))\n",
        "#             chromagram = pd.DataFrame(librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length, )).transpose()\n",
        "#             matrixC = []\n",
        "#             for i in range(len(chromagram[1])): #quell'[1] che sarebbe la prima corda conta solo per il range!\n",
        "#                 matrixC.append(sum(np.array(chromagram.iloc[0:i+1])))\n",
        "#             scChroma = []\n",
        "#             v_eff=[]\n",
        "#             for j in j_chroma:\n",
        "#                 w = 2 ** (j - 1)\n",
        "#                 v_eff = []\n",
        "#                 print(j)\n",
        "#                 for i in range(len(chromagram[1])):\n",
        "#                     #print(i)\n",
        "#                     if i>w and i<len(chromagram[1])-w: #l'[1] conta sempre e solo per il range, le corde le faccio tutte\n",
        "#                         v_eff.append(d(s_eff(i - w + 1, i - 1), s_eff(i, i + w)))\n",
        "#                     else:\n",
        "#                         v_eff.append(0)\n",
        "#                 scChroma.append(statistics.mean(v_eff))\n",
        "#             scChromaOUT.append((df.song[ii],df.artist[ii],scChroma))\n",
        "#     except:\n",
        "#         print(\"bababa\")\n",
        "\n",
        "\n",
        "# b=[]\n",
        "# c=[] #quelli da rifare + quelli che ho messo per la prima volta in b!!!!!!!!!!\n",
        "# bb=list(set([(df.song[x],df.artist[x]) for x in range(len(df.date))]))\n",
        "# for x in bb:\n",
        "#     if x[0] not in [x[0] for x in b]:\n",
        "#         b.append(x)\n",
        "#     else:\n",
        "#         c.append(x)\n",
        "\n",
        "# for x in b:\n",
        "#     if x[0] in [x[0] for x in c]:\n",
        "#         c.append(x)\n",
        "\n",
        "# temp = []\n",
        "# for x in ale:\n",
        "#     if x[0] not in [x[0] for x in temp]:\n",
        "#         temp.append(x)\n",
        "#     else:\n",
        "#          if isinstance([y[1] for y in temp if y[0]==x[0]][0],list):\n",
        "#             temp.remove([y[1] for y in temp if y[0]==x[0]][0])\n",
        "#             temp.append(x)\n",
        "\n",
        "# for el in range(len(c)):\n",
        "# #for i in list(len(df.date)):\n",
        "#     print(el)\n",
        "#     x, sr = librosa.load(\"{} - {}.mp3\".format(c[el][0],c[el][1]))\n",
        "#     chromagram = pd.DataFrame(librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length, )).transpose()\n",
        "#     matrixC = []\n",
        "#     for i in range(len(chromagram[1])): #quell'[1] che sarebbe la prima corda conta solo per il range!\n",
        "#         matrixC.append(sum(np.array(chromagram.iloc[0:i+1])))\n",
        "#     scChroma = []\n",
        "#     v_eff=[]\n",
        "#     for j in j_chroma:\n",
        "#         w = 2 ** (j - 1)\n",
        "#         v_eff = []\n",
        "#         print(j)\n",
        "#         for i in range(len(chromagram[1])): \n",
        "#             #print(i)\n",
        "#             if i>w and i<len(chromagram[1])-w: #l'[1] conta sempre e solo per il range, le corde le faccio tutte\n",
        "#                 v_eff.append(d(s_eff(i - w + 1, i - 1), s_eff(i, i + w)))\n",
        "#             else:\n",
        "#                 v_eff.append(0)\n",
        "#         scChroma.append(statistics.mean(v_eff))\n",
        "#     ale.append((c[el][0],c[el][1],scChroma))\n",
        "\n",
        "# fix=[(c[-i],ale[i]) for i in range(-283,1,1)]\n",
        "# ale=ale[:-284]\n",
        "# for x in fix:\n",
        "#     ale.append(x)\n",
        "\n",
        "# df[\"Chroma1\"],df[\"Chroma2\"],df[\"Chroma3\"],df[\"Chroma4\"],df[\"Chroma5\"],df[\"Chroma6\"]=0.0,0.0,0.0,0.0,0.0,0.0\n",
        "\n",
        "# for x in range(len(df.date)):\n",
        "#     try:\n",
        "#         el=[y for y in ale if y[0]==df.song[x]][0][-1]\n",
        "#         df[\"Chroma1\"][x],df[\"Chroma2\"][x],df[\"Chroma3\"][x],df[\"Chroma4\"][x],df[\"Chroma5\"][x],df[\"Chroma6\"][x]=el\n",
        "#     except:\n",
        "#         print(df.song[x])\n",
        "\n",
        "\n",
        "# #import pickle\n",
        "# #with open(os.getcwd()[:-6]+'done2.pkl', 'wb') as f:\n",
        "# #    pickle.dump(scChromaOUT, f)\n",
        "\n",
        "# #with open(os.getcwd()[:-6]+'done2.pkl', 'rb') as f:\n",
        "# #   ale = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsBq5jXryWnC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFjCHDj27g9q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ymcnJVd7g_8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWIrxSrR7hC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6VTGhSb7hFZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqvNMXMn7hIg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAlq1fDZyWp4"
      },
      "outputs": [],
      "source": [
        "#main \n",
        "\n",
        "#main \n",
        "\n",
        "# efficient implementation approach (py is not c++ ;)\n",
        "import os, librosa, numpy as np, pandas as pd, statistics, scipy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_excel(r\"C:\\Users\\alessio\\Desktop\\afterChroma.xlsx\", engine='openpyxl')\n",
        "os.chdir(r\"C:\\Users\\alessio\\Documents\\Tracks\")\n",
        "\n",
        "def kl_divergence(p, q):\n",
        "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
        "def d(s1, s2):\n",
        "    M = (s1 + s2) / 2\n",
        "    return (kl_divergence(s1, M) + kl_divergence(s2, M)) / 2\n",
        "def s_eff(a, b):\n",
        "    return matrixC[b] - matrixC[a]\n",
        "def eucl_dist(a, b):\n",
        "    return np.linalg.norm(a - b)\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "# timbre and arousal\n",
        "sr = 44100\n",
        "win_len = round(sr * 2.97)\n",
        "win = np.hamming(win_len)\n",
        "j_timbre = range(1, 7)\n",
        "\n",
        "#scTimbreOUT = []\n",
        "for ii in range(len(df.date)): #576,994, 2550\n",
        "    print(ii)\n",
        "    if (df.song[ii], df.artist[ii]) not in [(x[0], x[1]) for x in scTimbreOUT]:\n",
        "        print(df.song[ii],ii)\n",
        "        x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii],df.artist[ii]),sr)\n",
        "        d = round(librosa.get_duration(x, sr=sr))  # in seconds, COME CONSIDERO IL ROUNDING?!?!?!?\n",
        "        i, ls = 0, []\n",
        "        while i < d * sr:\n",
        "            a = x[i:i + win_len]  # win_len = datapoints in that window interval, +i <-- il movimento di 1 sec, (+0,+44100, +44100*2, ecc)\n",
        "            if len(x[i:i + win_len]) < win_len: #per l'ultimo pezzo magari non lungo abbastanza\n",
        "                a = np.array(list(x[i:i + win_len]) + [0 for x in range(win_len - len(x[i:i + win_len]))])\n",
        "            windowed_segment = win * a\n",
        "            ls_t = []\n",
        "            for y in range(0, len(windowed_segment), 512):\n",
        "                ls_t.append([x[0] for x in librosa.feature.mfcc(windowed_segment[y:y + 512], sr=sr, n_mfcc=36).tolist()]) #mettere lol[0:x con x>len(lol)] funge lo stesso\n",
        "            df1 = pd.DataFrame(ls_t).transpose()\n",
        "            ls.append([statistics.mean(df1.iloc[x]) for x in range(len(df1[35]))])\n",
        "            #print((d*sr - i)//sr)\n",
        "            i += sr\n",
        "        df1 = pd.DataFrame(ls)\n",
        "\n",
        "        matrixC = []\n",
        "        for i in range(len(df1[35])):\n",
        "            matrixC.append(sum(np.array(df1.iloc[0:i+1])))\n",
        "        scTimbre = []\n",
        "        v_eff=[]\n",
        "        for j in j_timbre:\n",
        "            w = 2 ** (j - 1)\n",
        "            v_eff = []\n",
        "            print(j)\n",
        "            for i in range(len(df1[35])):\n",
        "                if i>w and i<len(df1[35])-w:\n",
        "                    v_eff.append(eucl_dist(s_eff(i - w + 1, i - 1), s_eff(i, i + w))) #kl div serve per le prob distro, non è quello che cerco, uso la eucledian distance https://groups.google.com/g/librosa/c/9Xs15kDImOg\n",
        "                else:\n",
        "                    v_eff.append(0)\n",
        "            scTimbre.append(statistics.mean(v_eff))\n",
        "        scTimbreOUT.append((df.song[ii],df.artist[ii],scTimbre))\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open(r\"C:\\Users\\alessio\\Documents\\mfcc.pkl\", 'wb') as f:\n",
        "    pickle.dump(mfcc, f)\n",
        "\n",
        "with open(r\"C:\\Users\\alessio\\Documents\\arousalOUT.pkl\", 'rb') as f:\n",
        "   arousalOUT = pickle.load(f)\n",
        "\n",
        "# MFCC\n",
        "import os, librosa, numpy as np, pandas as pd, statistics, scipy\n",
        "df = pd.read_excel(r\"C:\\Users\\alessio\\Downloads\\afterAll.xlsx\", engine='openpyxl')\n",
        "os.chdir(r\"C:\\Users\\alessio\\Documents\\Tracks\")\n",
        "from sklearn.cluster import KMeans\n",
        "sr = 44100\n",
        "win_len = round(sr * 0.025)\n",
        "\n",
        "mfcc = []\n",
        "for ii in range(len(df.date)):\n",
        "    print(ii)\n",
        "    if (df.song[ii], df.artist[ii]) not in [(x[0], x[1]) for x in mfcc]:\n",
        "        print(df.song[ii],ii)\n",
        "        x, sr = librosa.load(\"{} - {}.mp3\".format(df.song[ii],df.artist[ii]),sr)\n",
        "        i, ls = 0, []\n",
        "        d = round(librosa.get_duration(x, sr=sr))\n",
        "        while i < d * sr:\n",
        "           windowed_segment = x[i:i + win_len]  # win_len = datapoints in that window interval, +i <-- il movimento di 1 sec, (+0,+44100, +44100*2, ecc)\n",
        "           if len(x[i:i + win_len]) < win_len:\n",
        "               windowed_segment = np.array(\n",
        "                   list(x[i:i + win_len]) + [0.0 for x in range(win_len - len(x[i:i + win_len]))])\n",
        "           ls.append(librosa.feature.mfcc(windowed_segment, sr=sr, n_mfcc=20))\n",
        "           i += round(0.015 * sr)\n",
        "\n",
        "        llss = []\n",
        "        for x in range(len(ls)):\n",
        "           for y in range(20):\n",
        "               llss.append(ls[x][y][0]), llss.append(ls[x][y][1]), llss.append(ls[x][y][2])\n",
        "\n",
        "        i, final = 0, []\n",
        "        while i < len(llss):\n",
        "           final.append([llss[x + i] for x in range(1, 60, 3)])\n",
        "           final.append([llss[x + i] for x in range(2, 60, 3)])\n",
        "           final.append([llss[x + i] for x in range(3, 60, 3)])\n",
        "           i += 60\n",
        "\n",
        "        df1 = pd.DataFrame(final)\n",
        "        mfcc.append((df.song[ii], df.artist[ii],df.genre[ii],[np.mean(df1[x]) for x in df1.columns]))  # credo che io debba fare l'average, il df di una singola canzone a 55k rows, se ce ne metto altre 4199 --> 230945000\n",
        "\n",
        "'''\n",
        "dovrai fare knn?? per genere, pero contando tutte e 4200 le righe, non solo 1800, ripartendo quindi dal dataset lo fai co list comprehension.\n",
        "'''\n",
        "import pickle\n",
        "with open(r\"C:\\Users\\alessio\\Desktop\\mfcc.pkl\", 'rb') as f:\n",
        "   mfcc = pickle.load(f)\n",
        "\n",
        "df[\"toDropMFCC\"]=\"Zero\"\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el = [y for y in mfcc if y[0]==df.song[x] and y[1]==df.artist[x]][0][-1] # and y[1]==df.artist[x]\n",
        "        df[\"toDropMFCC\"][x] = el\n",
        "    except:\n",
        "        print(df.song[x])\n",
        "#\n",
        "from sklearn.cluster import KMeans\n",
        "mfccOUT=[]\n",
        "for g in list(set([x[2] for x in mfcc])):\n",
        "    kmeans = KMeans(n_clusters=32, random_state=42).fit(list(df.iloc[[x for x in range(len(df.date)) if df.genre[x]==g]].toDropMFCC))\n",
        "    mfccOUT.append((g,kmeans.cluster_centers_))\n",
        "\n",
        "for x in range(20): #aoooo ma so fino a 20 no a 32, gli mfcc, 1,21 quindi; mi pesa il culo faccio (20)\n",
        "    df[\"mfcc{}\".format(x)]=0.0\n",
        "\n",
        "\n",
        "from scipy.spatial import distance\n",
        "def findTheRightCentroid(mfcc, centroid): #_20, _32_20\n",
        "    l=[(distance.euclidean(mfcc,centroid[x]),x) for x in range(32)]\n",
        "    spotMin = min([x[0] for x in l])\n",
        "    return [centroid[x[1]] for x in l if x[0]==spotMin][0]\n",
        "\n",
        "for x in range(len(df.date)):\n",
        "    rightCentroid=findTheRightCentroid(df[\"toDropMFCC\"][x], [y[1].tolist() for y in mfccOUT if df.genre[x]==y[0]][0]) #i pass the row + the right centroidS wrt song genre\n",
        "    df[\"mfcc1\"][x],df[\"mfcc2\"][x],df[\"mfcc3\"][x],df[\"mfcc4\"][x],df[\"mfcc5\"][x],df[\"mfcc6\"][x],df[\"mfcc7\"][x],df[\"mfcc8\"][x],df[\"mfcc9\"][x],df[\"mfcc10\"][x],df[\"mfcc11\"][x],df[\"mfcc12\"][x],df[\"mfcc13\"][x],df[\"mfcc14\"][x],df[\"mfcc15\"][x],df[\"mfcc16\"][x],df[\"mfcc17\"][x],df[\"mfcc18\"][x],df[\"mfcc19\"][x],df[\"mfcc0\"][x],=rightCentroid\n",
        "    #df[[\"mfcc{}\".format(x) for x in range(20)]].iloc[x] = rightCentroid #CI METTO I 20 COSI DEL CENTRODIE GIUSTO... BOH\n",
        "\n",
        "#df.to_excel(\"AfterDeath15Settembre.xlsx\")\n",
        "df1 = pd.read_excel(r\"C:\\Users\\alessio\\Desktop\\AfterDeath15Settembre.xlsx\", engine=\"openpyxl\")\n",
        "df[[\"mfcc{}\".format(x) for x in range(20)]] = df1[[\"mfcc{}\".format(x) for x in range(20)]]\n",
        "#df.to_excel(\"Rebirth.xlsx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################https://blog.floydhub.com/introduction-to-k-means-clustering-in-python-with-scikit-learn/\n",
        "\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el=[y for y in mfccOUT if df.genre[x]==y[0]][0][-1]\n",
        "        df[\"Timbre1\"][x],df[\"Timbre2\"][x],df[\"Timbre3\"][x],df[\"Timbre4\"][x],df[\"Timbre5\"][x],df[\"Timbre6\"][x]=el\n",
        "    except:\n",
        "        print(df.song[x])\n",
        "\n",
        "\n",
        "df1 = pd.DataFrame(mfcc)\n",
        "kmeans = KMeans(n_clusters=32, random_state=42).fit(df1)\n",
        "#kmeans.labels_\n",
        "mfccOUT.append(kmeans.cluster_centers_)\n",
        "\n",
        "######################################\n",
        "# with open(r\"C:\\Users\\alessio\\Documents\\scTimbreFive.pkl\", 'rb') as f:\n",
        "#    scTimbreOUT = pickle.load(f)\n",
        "\n",
        "df[\"Timbre1\"],df[\"Timbre2\"],df[\"Timbre3\"],df[\"Timbre4\"],df[\"Timbre5\"],df[\"Timbre6\"]=0.0,0.0,0.0,0.0,0.0,0.0\n",
        "\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el=[y for y in scTimbreOUT if y[0]==df.song[x] and y[1]==df.artist[x]][0][-1]\n",
        "        df[\"Timbre1\"][x],df[\"Timbre2\"][x],df[\"Timbre3\"][x],df[\"Timbre4\"][x],df[\"Timbre5\"][x],df[\"Timbre6\"][x]=el\n",
        "    except:\n",
        "        print(df.song[x])\n",
        "#\n",
        "# with open(r\"C:\\Users\\alessio\\Downloads\\done2.pkl\", 'rb') as f:\n",
        "#    chromaOUT = pickle.load(f)\n",
        "\n",
        "df[\"Chroma1\"],df[\"Chroma2\"],df[\"Chroma3\"],df[\"Chroma4\"],df[\"Chroma5\"],df[\"Chroma6\"]=0.0,0.0,0.0,0.0,0.0,0.0\n",
        "\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el=[y for y in scChromaOUT if y[0]==df.song[x] and y[1]==df.artist[x]][0][-1]\n",
        "        df[\"Chroma1\"][x],df[\"Chroma2\"][x],df[\"Chroma3\"][x],df[\"Chroma4\"][x],df[\"Chroma5\"][x],df[\"Chroma6\"][x]=el\n",
        "    except:\n",
        "        print(df.song[x])\n",
        "\n",
        "df[\"ArousalMean\"],df[\"ArousalSD\"]=0.0,0.0\n",
        "for x in range(len(df.date)):\n",
        "    try:\n",
        "        el = [y for y in arousalOUT if y[0]==df.song[x] and y[1]==df.artist[x]][0]\n",
        "        df[\"ArousalMean\"][x],df[\"ArousalSD\"][x] = el[2], el[3]\n",
        "    except:\n",
        "        print(df.song[x])\n",
        "\n",
        "\n",
        "######################################################################### 15 settembre testiamo sti cazzo di modelli\n",
        "import os, librosa, numpy as np, pandas as pd, statistics, scipy\n",
        "df = pd.read_excel(r\"C:\\Users\\alessio\\Desktop\\Rebirth.xlsx\", engine='openpyxl')\n",
        "# df = df.sort_values(by=\"uniq_id\")\n",
        "# df = df.reset_index()\n",
        "# df = df.drop(columns=\"index\")\n",
        "# df[\"Rank\"] = 0\n",
        "# i,j = 0, [x for x in range(50,0,-1)]\n",
        "# while i<=len(df.genre):\n",
        "#     df.iloc[i:i+50][\"Rank\"] = j\n",
        "#     i+=50\n",
        "\n",
        "# Chroma alone\n",
        "import statsmodels.api as sm\n",
        "my_cols = [\"Chroma1\",\"Chroma2\",\"Chroma3\",\"Chroma4\",\"Chroma5\",\"Chroma6\",]\n",
        "X = sm.add_constant(df[my_cols])\n",
        "results = sm.OLS(df.Rank, X).fit().summary()\n",
        "print(results)\n",
        "\n",
        "# Timbre alone\n",
        "import statsmodels.api as sm\n",
        "my_cols = [\"Timbre1\",\"Timbre2\",\"Timbre3\",\"Timbre4\",\"Timbre5\",\"Timbre6\",]\n",
        "X = sm.add_constant(df[my_cols])\n",
        "results = sm.OLS(df.Rank, X).fit().summary()\n",
        "print(results)\n",
        "\n",
        "# Arousal alone\n",
        "import statsmodels.api as sm\n",
        "my_cols = [\"ArousalSD\",\"ArousalMean\"]\n",
        "X = sm.add_constant(df[my_cols])\n",
        "results = sm.OLS(df.Rank, X).fit().summary()\n",
        "print(results)\n",
        "\n",
        "#Mfcc alone\n",
        "import statsmodels.api as sm\n",
        "my_cols = [\"mfcc{}\".format(x) for x in range(20)] + [\"Chroma1\",\"Chroma2\",\"Chroma3\",\"Chroma4\",\"Chroma5\",\"Chroma6\",] +[\"ArousalSD\",\"ArousalMean\"] + [\"Timbre1\",\"Timbre2\",\"Timbre3\",\"Timbre4\",\"Timbre5\",\"Timbre6\",]\n",
        "X = sm.add_constant(df[my_cols])\n",
        "results = sm.OLS(df.Rank, X).fit().summary()\n",
        "print(results)\n",
        "\n",
        "###################### 2° parte del Modelling, 16 settembre 2021\n",
        "import os, librosa, numpy as np, pandas as pd, statistics, scipy\n",
        "df = pd.read_excel(r\"C:\\Users\\alessio\\Desktop\\Rebirth.xlsx\", engine='openpyxl')\n",
        "#df[list(df1.columns)[-35:]] = df1[[list(df1.columns)[-35:]][0]]\n",
        "\n",
        "\n",
        "# Random Forest Model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "my_cols= my_cols + [\"lsm\"]+[\"Chroma1\",\"Chroma2\",\"Chroma3\",\"Chroma4\",\"Chroma5\",\"Chroma6\",] +[\"ArousalSD\",\"ArousalMean\"] + [\"Timbre1\",\"Timbre2\",\"Timbre3\",\"Timbre4\",\"Timbre5\",\"Timbre6\",]\n",
        "my_cols=my_cols    + list(df.columns)[-1126-1885:-1126]\n",
        "\n",
        "my_cols.append(\"Rank\")\n",
        "df1 = df[my_cols]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df1.drop(columns=[\"Rank\"]), df1[\"Rank\"], test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42, bootstrap= True, max_depth= 10, min_samples_leaf =1, min_samples_split =10, n_estimators =1000)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "predictions = rf.predict(X_test)\n",
        "errors = abs(predictions - y_test)\n",
        "mean_absolute_error(y_test, predictions)\n",
        "mean_squared_error(y_test,predictions, squared=True)\n",
        "\n",
        "# Grid for GridSearchCV\n",
        "grid_rf = {'n_estimators': [200, 1000],\n",
        "           'max_depth': [10, 100],\n",
        "           'min_samples_split': [2, 10],\n",
        "           'min_samples_leaf': [1, 4],\n",
        "           'bootstrap': [True, False]}\n",
        "\n",
        "# GridSearch and Model Fit\n",
        "something_rf = GridSearchCV(RandomForestRegressor(), param_grid=grid_rf, cv=5, verbose=2)\n",
        "something_rf.fit(X_train, y_train)\n",
        "something_rf.best_params_ #{'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
        "predictions = something.predict(X_test)\n",
        "errors = abs(predictions - y_test)\n",
        "\n",
        "mean_squared_error(y_test, predictions, squared=True)\n",
        "mean_absolute_error(y_test, predictions)\n",
        "scores_rf = cross_val_score(\n",
        "    RandomForestRegressor(random_state=42, n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_depth=100,\n",
        "                          bootstrap=True), df.drop(columns=[\"cost\"]), df[\"cost\"],\n",
        "    cv=10)  # df.drop(columns=[\"cost\"]), df[\"cost\"], cv=10)\n",
        "scores_rf.mean()\n",
        "\n",
        "\n",
        "#SVMMMMMMMMMMMMMMMMM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X, y = df1.drop(columns=[\"Rank\"]), df1[\"Rank\"]\n",
        "sc_X = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "X = sc_X.fit_transform(X)\n",
        "y = sc_y.fit_transform(np.array(y).reshape(-1,1))\n",
        "#df1=df1.drop(columns=\"Rank\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "regressor = SVR(kernel='rbf')\n",
        "regressor.fit(X_train,y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "mean_squared_error(y_test, y_pred)\n",
        "mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "\n",
        "my_col1 = [\"Rank\"]+[\"Chroma1\",\"Chroma2\",\"Chroma3\",\"Chroma4\",\"Chroma5\",\"Chroma6\",] +[\"ArousalSD\",\"ArousalMean\"] + [\"Timbre1\",\"Timbre2\",\"Timbre3\",\"Timbre4\",\"Timbre5\",\"Timbre6\",]\n",
        "df1 = df[my_col1]\n",
        "\n",
        "my_cols2=[\"Rank\"]+[x for x in my_cols if x not in my_col1]\n",
        "df1 = df[my_cols2]\n",
        "\n",
        "df1 = df[my_cols]\n",
        "\n",
        "# SHAPPPPPPPPPPPPPPPPPPPPPP\n",
        "rf = RandomForestRegressor(random_state=42, bootstrap= True, max_depth= 10, min_samples_leaf =1, min_samples_split =10, n_estimators =1000)\n",
        "rf.fit(X,y)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "rf.feature_importances_\n",
        "plt.barh(list(df1.drop(columns=[\"Rank\"]).columns), rf.feature_importances_)\n",
        "\n",
        "sorted_idx = rf.feature_importances_.argsort()\n",
        "plt.barh(np.array(list(df1.drop(columns=[\"Rank\"]).columns))[sorted_idx], rf.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Random Forest Feature Importance\")\n",
        "\n",
        "import shap\n",
        "explainer = shap.TreeExplainer(rf)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "shap.summary_plot(shap_values, X_train, feature_names=list(df1.drop(columns=[\"Rank\"]).columns))\n",
        "\n",
        "shap.summary_plot(shap_values, X_train, feature_names=list(df1.drop(columns=[\"Rank\"]).columns), plot_type=\"bar\")\n",
        "\n",
        "shap.dependence_plot(3, shap_values, X_train, feature_names=list(df1.drop(columns=[\"Rank\"]).columns))\n",
        "\n",
        "shap.decision_plot(explainer.expected_value[0], shap_values[:100], feature_names = list(df1.drop(columns=[\"Rank\"]).columns))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
